{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnXlJSpRjCA10RPUzk7h1/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKCAnEJKox69",
        "outputId": "91377939-fb94-4dc9-ac3d-5c3b53cd313a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão: [[4, 1], [2, 3]]\n",
            "Sensibilidade (Recall): 0.6\n",
            "Precisão (Precision): 0.75\n",
            "Acurácia: 0.7\n",
            "F-Score: 0.6666666666666665\n",
            "Especificidade: 0.8\n"
          ]
        }
      ],
      "source": [
        "def confusion_matrix_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula matriz de confusão e métricas de classificação binária\n",
        "    y_true: lista de valores reais (0 ou 1)\n",
        "    y_pred: lista de valores previstos (0 ou 1)\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa contadores\n",
        "    TP = TN = FP = FN = 0\n",
        "\n",
        "    for real, pred in zip(y_true, y_pred):\n",
        "        if real == 1 and pred == 1:\n",
        "            TP += 1\n",
        "        elif real == 0 and pred == 0:\n",
        "            TN += 1\n",
        "        elif real == 0 and pred == 1:\n",
        "            FP += 1\n",
        "        elif real == 1 and pred == 0:\n",
        "            FN += 1\n",
        "\n",
        "    # Cálculo das métricas\n",
        "    sensibilidade = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
        "    precisao = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    acuracia = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "    f_score = (2 * precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) > 0 else 0\n",
        "    especificidade = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "    matriz_confusao = [[TN, FP],\n",
        "                       [FN, TP]]\n",
        "\n",
        "    return {\n",
        "        \"Matriz de Confusão\": matriz_confusao,\n",
        "        \"Sensibilidade (Recall)\": sensibilidade,\n",
        "        \"Precisão (Precision)\": precisao,\n",
        "        \"Acurácia\": acuracia,\n",
        "        \"F-Score\": f_score,\n",
        "        \"Especificidade\": especificidade\n",
        "    }\n",
        "\n",
        "\n",
        "# ---- EXEMPLO DE USO ----\n",
        "y_real = [1, 0, 1, 1, 0, 0, 1, 0, 1, 0]   # valores verdadeiros\n",
        "y_previsto = [1, 0, 1, 0, 0, 1, 1, 0, 0, 0]  # valores previstos pelo modelo\n",
        "\n",
        "resultados = confusion_matrix_metrics(y_real, y_previsto)\n",
        "\n",
        "for k, v in resultados.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    }
  ]
}